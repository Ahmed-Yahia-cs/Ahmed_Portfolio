<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Arabic Autocompleting System | Ahmed Yahia</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="A system that suggests the next Arabic words in the same context">
    <meta name="generator" content="Hugo 0.101.0" />
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="Arabic Autocompleting System" />
<meta property="og:description" content="A system that suggests the next Arabic words in the same context" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/post/project-1/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-01-25T10:58:08-04:00" />
<meta property="article:modified_time" content="2022-01-25T10:58:08-04:00" /><meta property="og:site_name" content="Ahmed Yahia" />

<meta itemprop="name" content="Arabic Autocompleting System">
<meta itemprop="description" content="A system that suggests the next Arabic words in the same context"><meta itemprop="datePublished" content="2022-01-25T10:58:08-04:00" />
<meta itemprop="dateModified" content="2022-01-25T10:58:08-04:00" />
<meta itemprop="wordCount" content="1207">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Arabic Autocompleting System"/>
<meta name="twitter:description" content="A system that suggests the next Arabic words in the same context"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  <header class="cover bg-top" style="background-image: url('https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/images/arabic_alpha.jpg');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Ahmed Yahia
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/post/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
    <a href="https://www.linkedin.com/in/ahmed-yahia-b91586218/" target="_blank" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    <a href="https://github.com/Ahmed-Yahia-cs" target="_blank" class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel="noopener" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Arabic Autocompleting System</h1>
          
            <h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              A system that suggests the next Arabic words in the same context
            </h2>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        PROJECTS
      </aside>
      











      <h1 class="f1 athelas mt3 mb1">Arabic Autocompleting System</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2022-01-25T10:58:08-04:00">January 25, 2022</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h2 id="introduction">Introduction</h2>
<p>Auto-Complete is a feature that provides relevant suggestions based on input by the user. It works best in domains with a limited number of possible words. There are many applications that is used for such as:</p>
<ol>
<li>Autocomplete search engine</li>
<li>Command line interpreters</li>
<li>Source Code Editors.</li>
</ol>
<p>Language models are divided into two types :</p>
<ol>
<li>Probabilistic methods</li>
<li>Neural Network Based</li>
</ol>
<p>But, as it always is, some problems need to be solved first. These problems
can be divided into two categories:</p>
<ol>
<li>
<p>Issues related to data:</p>
<ol>
<li>Large amounts of data: The amount of data generated daily is
genuinely enormous. To process and analyze it, we need time and
power. Massive data centers are built for this purpose, but the best
language models still train for weeks and take a lot of space, and these
models are becoming more prominent all the time.</li>
<li>Low quality: A considerable portion of data generated is not of a
particular quality. It needs some preprocessing, which takes time and
money. It is, therefore, relatively expensive and time-consuming to
work with text data.</li>
</ol>
</li>
<li>
<p>Problems related to the language itself.</p>
<ol>
<li>Context: Same words may have different meanings depending on the
context, while some words may have similar pronunciation but
different meanings.</li>
<li>Domain-specific language : Vocabulary across industries may differ
quite a lot. Thus, it is challenging to create a universal model. Usually,
it is a better idea to train models on data related to one particular
industry.</li>
<li>complexity: Human language has many complex mechanisms that are
difficult for machines. Also, language changes from sentence to
sentence and from author to author.</li>
</ol>
</li>
</ol>
<h2 id="training-dataset">Training Dataset</h2>
<p>Masader is the first online catalog for Arabic NLP datasets. This catalog contains 200 datasets with more than 25 metadata annotations for each dataset. We approached Masader to find a suitable dataset for our task. There were 11 available datasets related to text generation.Out of all these 11 sources, only two were chosen to be used due to limited
resources. Almasralyoum which was used to train all our models and youm7 which was only used in fine tuning the transformer along with Almasralyoum.
<img src="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/images/dataset.png" alt="Dataset"></p>
<h2 id="model-methodologies">Model Methodologies</h2>
<h3 id="statistical-model-baseline">Statistical Model (Baseline)</h3>
<p>Statistical language models are the type of models that assign probabilities to the sequences of words like N-gram Language Model. N-gram is the sequence of N words, by that notion, a 2-gram (or bigram) is a two-word sequence of words, and a 3-gram (or trigram) is a three-word sequence of words and so on. This shortcoming and ways to decompose the probability function using the chain rule serves as the base intuition of the N-gram model. Here, you, instead of computing probability using the entire corpus, would approximate it by just a few historical words. In our case, we used the trigram model. The trigram model approximates the probability of a word given all the previous words by using only the conditional probability of two preceding words. In other words, you
approximate it with the probability: P(w3 | (w1,w2) ). The trigram model is a dictionary of a dictionary, with key = n-gram (context) and value = dictionary of (key = word , value = probability ) as probability distributions of the next words.</p>
<p>Pros :</p>
<ol>
<li>Very Fast during inference.</li>
<li>Simple to create.</li>
</ol>
<p>Cons:</p>
<ol>
<li>Have a large size.</li>
<li>Out of Vocabulary.
<img src="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/images/ngrams.png" alt="N-grams"></li>
</ol>
<h3 id="rnn-language-models">RNN Language Models</h3>
<p>Recurrent Neural Networks (RNNs) are ideal for sequential data such as text, where the sequence is more important.
There are two main dichotomies when using RNNs for text, character and word-level models. This refers to the way that text is encoded into integers or the model to process. In char-level models, we tokenize each letter into
a one-hot vector from the corpus of letters. In word-level models, we tokenize each word into a one-hot vector from the corpus of words.</p>
<table>
<thead>
<tr>
<th>Word Level</th>
<th>Character Level</th>
</tr>
</thead>
<tbody>
<tr>
<td>Higher accuracy and lower computational cost</td>
<td>Lower accuracy and higher computational cost</td>
</tr>
<tr>
<td>Works better with Longer Short Term Memory (LSTM)</td>
<td>Works poorer with Longer Short Term Memory (LSTM)</td>
</tr>
<tr>
<td>Can not deal with OOV or misspelled words</td>
<td>Can deal with OOV or misspelled words</td>
</tr>
<tr>
<td>Different meanings of very similar words</td>
<td>Not carry any meaning or information as word-based</td>
</tr>
<tr>
<td><img src="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/images/rnn.png" alt="Dataset"></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="transformers">Transformers</h3>
<p>Neural networks usually process language by generating fixed- or
variable-length vector-space representations. After starting with
representations of individual words or even pieces of words, they aggregate information from surrounding words to determine the meaning of a given bit of language in context. For example, deciding on the most likely meaning and appropriate representation of the word “bank” in the sentence
“I arrived at the bank after crossing the…” requires knowing if the sentence ends in “&hellip; road.” or “&hellip; river.”</p>
<p>RNNs have in recent years become the typical network architecture for translation, processing language sequentially in a left-to-right or right-to-left fashion. Reading one word at a time, this forces RNNs to perform multiple steps to make decisions that depend on words far away from each other. Processing the example above, an RNN could only determine that “bank” is likely to refer to the bank of a river after reading
each word between “bank” and “river” step by step. Prior research has shown that, roughly speaking, the more such steps decisions require, the harder it is for a recurrent network to learn how to make those decisions.</p>
<p>The sequential nature of RNNs also makes it more difficult to fully take advantage of modern fast computing devices such as TPUs and GPUs, which excel at parallel and not sequential processing. Convolutional neural networks (CNNs) are much less sequential than RNNs, but in CNN architectures like ByteNet or ConvS2S the number of steps required to combine information from distant parts of the input still grows with increasing distance.</p>
<p>In contrast, the Transformer only performs a small, constant number of steps (chosen empirically). In each step, it applies a self-attention mechanism which directly models relationships between all words in a sentence, regardless of their respective position.</p>
<p>In the earlier example “I arrived at the bank after crossing the river”, to determine that the word “bank” refers to the shore of a river and not a financial institution, the Transformer can learn to immediately attend to the word “river” and make this decision in a single step.
<img src="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/images/transformer.png" alt="Dataset"></p>
<h2 id="app-development--deployment">App Development &amp; Deployment</h2>
<p>The model API made using a new easy to use web framework which is FastAPI.</p>
<p>FastAPI works similarly to Flask which supports the deployment of web applications with a minimal amount of code. However, FastAPI is faster compared to Flask as it is built on ASGI (Asynchronous Server Gateway Interface) whereby it supports concurrency / asynchron.</p>
<p>Another problem with flask is that there is no data validation, meaning that we can pass any type of data being it string, tuple, numbers, or any
character. This can break the program often; you can create a data checker before passing the values further but it would add up additional work. The error pages in Flask are simple HTML pages that can raise decoder errors when the API is being called in other applications and no automated
docs generation system. You need to manually design the user interface for the usage and examples of the API. All these issues are resolved in the new framework.ous code whereas Flask uses WSGI (Web Server Gateway Interface).</p>
<p><img src="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/images/ara_auto_1.png" alt="FastAPI"></p>
<p><strong>github Repository:</strong> <a href="https://github.com/Ahmed-Yahia-cs/Arabic-Autocomplete-System">https://github.com/Ahmed-Yahia-cs/Arabic-Autocomplete-System</a></p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://ahmed-yahia-cs.github.io/Ahmed_Portfolio/" >
    &copy;  Ahmed Yahia 2022 
  </a>
    <div>
<div class="ananke-socials">
  
    <a href="https://www.linkedin.com/in/ahmed-yahia-b91586218/" target="_blank" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    <a href="https://github.com/Ahmed-Yahia-cs" target="_blank" class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel="noopener" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
